version: '3.8'
services:
  ml-inference:
    build: .
    ports:
      - "8080:8080"
