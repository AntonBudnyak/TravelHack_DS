version: '3.8'
services:
  ml-inference:
    build: .
    ports:
      - "1312:8080"
